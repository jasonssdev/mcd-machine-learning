{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d010f97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Módulos básicos para análisis y manipulación de datos\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Modelos de clasificación\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# Módulos para evaluación de modelos\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "\n",
    "# Módulos para el balanceo de datos\n",
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss\n",
    "from imblearn.over_sampling import RandomOverSampler, ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9f0a10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.paths import DATA_RAW_DIR\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d19043fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "path_data = DATA_RAW_DIR / 'post_pabellon.xlsx'\n",
    "print(Path(path_data).exists())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcff2911",
   "metadata": {},
   "source": [
    "1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9547884",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = None      # Variable que debe modificar\n",
    "y = None          # Variable que debe modificar\n",
    "X = None          # Variable que debe modificar\n",
    "\n",
    "# your code here\n",
    "\n",
    "# cargar dataframe\n",
    "datos = pd.read_excel(path_data, sheet_name='Datos')\n",
    "\n",
    "# separar variable objetivo\n",
    "X = datos.drop(columns=['HOSPITALIZACION'], axis=1)\n",
    "y = datos['HOSPITALIZACION']\n",
    "\n",
    "# crear variables dummies\n",
    "X = pd.get_dummies(X, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40438baf",
   "metadata": {},
   "source": [
    "2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ed1a623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividir en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c5bfc0",
   "metadata": {},
   "source": [
    "3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "550fd63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_model = SVC(C=15, kernel='poly', degree=2)\n",
    "RF_model = RandomForestClassifier(\n",
    "    n_estimators=50, max_depth=10, random_state=123, max_samples=0.8, max_features='log2')\n",
    "NB_model = BernoulliNB(class_prior=[0.5, 0.5])\n",
    "\n",
    "# your code here\n",
    "\n",
    "# stratified k fold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
    "\n",
    "# funcion de cross vaalidation\n",
    "\n",
    "\n",
    "def cv(X, y):\n",
    "\n",
    "    recall_svc = cross_val_score(SVC_model, X, y, cv=skf, scoring='recall')\n",
    "    recall_rf = cross_val_score(RF_model, X, y, cv=skf, scoring='recall')\n",
    "    recall_gnb = cross_val_score(NB_model, X, y, cv=skf, scoring='recall')\n",
    "\n",
    "    precision_svc = cross_val_score(SVC_model, X, y, cv=skf, scoring=metrics.make_scorer(metrics.precision_score, zero_division=0))\n",
    "\n",
    "    precision_rf = cross_val_score(RF_model, X, y, cv=skf, scoring=metrics.make_scorer(metrics.precision_score, zero_division=0))\n",
    "    precision_gnb = cross_val_score(NB_model, X, y, cv=skf, scoring=metrics.make_scorer(metrics.precision_score, zero_division=0))\n",
    "\n",
    "    accuracy_svc = cross_val_score(SVC_model, X, y, cv=skf, scoring='accuracy')\n",
    "    accuracy_rf = cross_val_score(RF_model, X, y, cv=skf, scoring='accuracy')\n",
    "    accuracy_gnb = cross_val_score(NB_model, X, y, cv=skf, scoring='accuracy')\n",
    "\n",
    "    f1_svc = cross_val_score(SVC_model, X, y, cv=skf, scoring='f1')\n",
    "    f1_rf = cross_val_score(RF_model, X, y, cv=skf, scoring='f1')\n",
    "    f1_gnb = cross_val_score(NB_model, X, y, cv=skf, scoring='f1')\n",
    "\n",
    "    auc_svc = cross_val_score(SVC_model, X, y, cv=skf, scoring='roc_auc')\n",
    "    auc_rf = cross_val_score(RF_model, X, y, cv=skf, scoring='roc_auc')\n",
    "    auc_gnb = cross_val_score(NB_model, X, y, cv=skf, scoring='roc_auc')\n",
    "\n",
    "    cv_results = pd.DataFrame(\n",
    "        index=['SV', 'RF', 'NB'],\n",
    "        columns=['Accuracy', 'Precision', 'Recall', 'F1', 'AUC'])\n",
    "\n",
    "    cv_results.loc['SV'] = [\n",
    "        accuracy_svc.mean(),\n",
    "        precision_svc.mean(),\n",
    "        recall_svc.mean(),\n",
    "        f1_svc.mean(),\n",
    "        auc_svc.mean()\n",
    "    ]\n",
    "    cv_results.loc['RF'] = [\n",
    "        accuracy_rf.mean(),\n",
    "        precision_rf.mean(),\n",
    "        recall_rf.mean(),\n",
    "        f1_rf.mean(),\n",
    "        auc_rf.mean()\n",
    "    ]\n",
    "    cv_results.loc['NB'] = [\n",
    "        accuracy_gnb.mean(),\n",
    "        precision_gnb.mean(),\n",
    "        recall_gnb.mean(),\n",
    "        f1_gnb.mean(),\n",
    "        auc_gnb.mean()\n",
    "    ]\n",
    "\n",
    "    return cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6060105f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Accuracy",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Precision",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Recall",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "F1",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "AUC",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "d9450bfd-6484-4ef4-a993-1f3adcf4316c",
       "rows": [
        [
         "SV",
         "0.9572151898734177",
         "0.0",
         "0.0",
         "0.0",
         "0.7353070175438596"
        ],
        [
         "RF",
         "0.959746835443038",
         "0.3",
         "0.13333333333333333",
         "0.18",
         "0.8557017543859649"
        ],
        [
         "NB",
         "0.8388291139240506",
         "0.05149572649572649",
         "0.1833333333333333",
         "0.0789406671759613",
         "0.6194078947368421"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SV</th>\n",
       "      <td>0.957215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.735307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.959747</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.855702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NB</th>\n",
       "      <td>0.838829</td>\n",
       "      <td>0.051496</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>0.078941</td>\n",
       "      <td>0.619408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Accuracy Precision    Recall        F1       AUC\n",
       "SV  0.957215       0.0       0.0       0.0  0.735307\n",
       "RF  0.959747       0.3  0.133333      0.18  0.855702\n",
       "NB  0.838829  0.051496  0.183333  0.078941  0.619408"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = cv(X_train, y_train)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e734b1",
   "metadata": {},
   "source": [
    "5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad6e7e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Accuracy",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Precision",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Recall",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "F1",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "AUC",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "0da57ee5-5823-46e5-ab5e-39ffb4b97b6d",
       "rows": [
        [
         "SV",
         "0.9590643274853801",
         "0.0",
         "0.0",
         "0.0",
         "0.5"
        ],
        [
         "RF",
         "0.9590643274853801",
         "0.0",
         "0.0",
         "0.0",
         "0.5"
        ],
        [
         "NB",
         "0.8538011695906432",
         "0.09090909090909091",
         "0.2857142857142857",
         "0.13793103448275862",
         "0.5818815331010452"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SV</th>\n",
       "      <td>0.959064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.959064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NB</th>\n",
       "      <td>0.853801</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.581882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Accuracy Precision    Recall        F1       AUC\n",
       "SV  0.959064       0.0       0.0       0.0       0.5\n",
       "RF  0.959064       0.0       0.0       0.0       0.5\n",
       "NB  0.853801  0.090909  0.285714  0.137931  0.581882"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_set(X,y):\n",
    "\n",
    "    SVC_model = SVC(C=15, kernel='poly', degree=2)\n",
    "    RF_model = RandomForestClassifier(n_estimators=50, max_depth=10, random_state=123, max_samples=0.8, max_features='log2')\n",
    "    NB_model = BernoulliNB(class_prior=[0.5, 0.5])\n",
    "\n",
    "    SVC_model.fit(X, y)\n",
    "    RF_model.fit(X, y)\n",
    "    NB_model.fit(X, y)\n",
    "\n",
    "    y_pred_svc = SVC_model.predict(X_test)\n",
    "    y_pred_rf = RF_model.predict(X_test)\n",
    "    y_pred_gnb = NB_model.predict(X_test)\n",
    "\n",
    "    accuracy_svc = metrics.accuracy_score(y_test, y_pred_svc)\n",
    "    accuracy_rf = metrics.accuracy_score(y_test, y_pred_rf)\n",
    "    accuracy_gnb = metrics.accuracy_score(y_test, y_pred_gnb)\n",
    "\n",
    "    precision_svc = metrics.precision_score(y_test, y_pred_svc, zero_division=0)\n",
    "    precision_rf = metrics.precision_score(y_test, y_pred_rf, zero_division=0)\n",
    "    precision_gnb = metrics.precision_score(y_test, y_pred_gnb, zero_division=0)\n",
    "\n",
    "    recall_svc = metrics.recall_score(y_test, y_pred_svc,zero_division=0)\n",
    "    recall_rf = metrics.recall_score(y_test, y_pred_rf, zero_division=0)\n",
    "    recall_gnb = metrics.recall_score(y_test, y_pred_gnb, zero_division=0)\n",
    "\n",
    "    f1_svc = metrics.f1_score(y_test, y_pred_svc, zero_division=0)\n",
    "    f1_rf = metrics.f1_score(y_test, y_pred_rf, zero_division=0)\n",
    "    f1_gnb = metrics.f1_score(y_test, y_pred_gnb, zero_division=0)\n",
    "    \n",
    "    auc_svc = metrics.roc_auc_score(y_test, y_pred_svc)\n",
    "    auc_rf = metrics.roc_auc_score(y_test, y_pred_rf)\n",
    "    auc_gnb = metrics.roc_auc_score(y_test, y_pred_gnb)\n",
    "    \n",
    "    test_results = pd.DataFrame(index=['SV', 'RF', 'NB'], columns=['Accuracy', 'Precision', 'Recall', 'F1', 'AUC'])\n",
    "    test_results.loc['SV'] = [accuracy_svc, precision_svc, recall_svc, f1_svc, auc_svc]\n",
    "    test_results.loc['RF'] = [accuracy_rf, precision_rf, recall_rf, f1_rf, auc_rf]\n",
    "    test_results.loc['NB'] = [accuracy_gnb, precision_gnb, recall_gnb, f1_gnb, auc_gnb]\n",
    "\n",
    "    return test_results\n",
    "    \n",
    "test_results = test_set(X_train, y_train)\n",
    "test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efac370d",
   "metadata": {},
   "source": [
    "6. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0badeb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Accuracy Precision    Recall        F1       AUC\n",
      "SV  0.651316  0.589468       1.0  0.741624  0.691118\n",
      "RF  0.988158  0.976954       1.0   0.98832  0.998979\n",
      "NB  0.664474  0.650265  0.718421  0.682299  0.757185\n",
      "    Accuracy Precision    Recall        F1       AUC\n",
      "SV  0.345029  0.058824       1.0  0.111111  0.658537\n",
      "RF   0.94152  0.333333  0.428571     0.375  0.695993\n",
      "NB  0.555556      0.04  0.428571  0.073171  0.494774\n"
     ]
    }
   ],
   "source": [
    "# over_sampling\n",
    "oversample = RandomOverSampler(sampling_strategy='minority', random_state=123)\n",
    "\n",
    "X_train_ros, y_train_ros = oversample.fit_resample(X_train, y_train)\n",
    "\n",
    "cv_results_balanced = cv(X_train_ros, y_train_ros)\n",
    "print(cv_results_balanced)\n",
    "\n",
    "test_results_balanced = test_set(X_train_ros, y_train_ros)\n",
    "print(test_results_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bea7bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Accuracy Precision    Recall        F1       AUC\n",
      "SV  0.466667  0.419048  0.483333  0.415238       0.4\n",
      "RF  0.609524  0.497619  0.733333  0.591169  0.616667\n",
      "NB   0.37619      0.42  0.516667  0.450794  0.236111\n",
      "    Accuracy Precision    Recall        F1       AUC\n",
      "SV  0.345029  0.051282  0.857143  0.096774  0.590157\n",
      "RF  0.777778  0.121951  0.714286  0.208333  0.747387\n",
      "NB  0.526316  0.059524  0.714286   0.10989  0.616289\n"
     ]
    }
   ],
   "source": [
    "# under_sampling\n",
    "undersample = RandomUnderSampler(sampling_strategy='majority', random_state=123)\n",
    "\n",
    "X_train_rus, y_train_rus = undersample.fit_resample(X_train, y_train)\n",
    "\n",
    "cv_results_balanced2 = cv(X_train_rus, y_train_rus)\n",
    "print(cv_results_balanced2)\n",
    "\n",
    "test_results_balanced2 = test_set(X_train_rus, y_train_rus)\n",
    "print(test_results_balanced2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff78856d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NearMiss - CV Results\n",
      "    Accuracy Precision    Recall        F1       AUC\n",
      "SV  0.609524  0.616667  0.466667  0.496667  0.694444\n",
      "RF  0.638095  0.733333       0.4  0.484762  0.752778\n",
      "NB  0.466667       0.3       0.1  0.146667  0.469444\n",
      "NearMiss - Test Results\n",
      "    Accuracy Precision    Recall        F1       AUC\n",
      "SV  0.362573  0.044643  0.714286  0.084034  0.530923\n",
      "RF  0.467836  0.053191  0.714286   0.09901  0.585801\n",
      "NB  0.748538  0.071429  0.428571  0.122449  0.595383\n",
      "ADASYN - CV Results\n",
      "    Accuracy Precision    Recall        F1       AUC\n",
      "SV  0.670626  0.610545  0.941965  0.740775  0.809318\n",
      "RF  0.945974  0.919117  0.978947  0.947704  0.990169\n",
      "NB  0.782581  0.729111  0.902386  0.805981  0.847236\n",
      "ADASYN - Test Results\n",
      "    Accuracy Precision    Recall        F1       AUC\n",
      "SV   0.45614      0.07       1.0  0.130841  0.716463\n",
      "RF  0.900585  0.222222  0.571429      0.32  0.743031\n",
      "NB  0.573099  0.054054  0.571429  0.098765    0.5723\n",
      "Combinación ROS+RUS - CV Results\n",
      "    Accuracy Precision    Recall        F1       AUC\n",
      "SV  0.677193  0.687013  0.126316  0.203222  0.745118\n",
      "RF  0.989474  0.969744       1.0  0.984549  0.999342\n",
      "NB  0.650877  0.485061  0.726316  0.581063   0.74813\n",
      "Combinación ROS+RUS - Test Results\n",
      "    Accuracy Precision    Recall        F1       AUC\n",
      "SV  0.923977     0.125  0.142857  0.133333  0.550087\n",
      "RF  0.947368  0.416667  0.714286  0.526316  0.835801\n",
      "NB  0.561404  0.052632  0.571429  0.096386  0.566202\n"
     ]
    }
   ],
   "source": [
    "# NearMiss\n",
    "nm = NearMiss(sampling_strategy='majority')\n",
    "X_train_nm, y_train_nm = nm.fit_resample(X_train, y_train)\n",
    "cv_results_balanced_nm = cv(X_train_nm, y_train_nm)\n",
    "test_results_balanced_nm = test_set(X_train_nm, y_train_nm)\n",
    "\n",
    "# ADASYN\n",
    "ad = ADASYN(random_state=123, sampling_strategy='minority')\n",
    "X_train_ad, y_train_ad = ad.fit_resample(X_train, y_train)\n",
    "cv_results_balanced_ad = cv(X_train_ad, y_train_ad)\n",
    "test_results_balanced_ad = test_set(X_train_ad, y_train_ad)\n",
    "\n",
    "# Combinación de RandomOverSampler y RandomUnderSampler\n",
    "ros = RandomOverSampler(random_state=123, sampling_strategy=0.5)\n",
    "rus = RandomUnderSampler(random_state=123, sampling_strategy=0.5)\n",
    "X_train_comb, y_train_comb = ros.fit_resample(X_train, y_train)\n",
    "X_train_comb, y_train_comb = rus.fit_resample(X_train_comb, y_train_comb)\n",
    "cv_results_balanced_comb = cv(X_train_comb, y_train_comb)\n",
    "test_results_balanced_comb = test_set(X_train_comb, y_train_comb)\n",
    "\n",
    "print('NearMiss - CV Results')\n",
    "print(cv_results_balanced_nm)\n",
    "print('NearMiss - Test Results')\n",
    "print(test_results_balanced_nm)\n",
    "\n",
    "print('ADASYN - CV Results')\n",
    "print(cv_results_balanced_ad)\n",
    "print('ADASYN - Test Results')\n",
    "print(test_results_balanced_ad)\n",
    "\n",
    "print('Combinación ROS+RUS - CV Results')\n",
    "print(cv_results_balanced_comb)\n",
    "print('Combinación ROS+RUS - Test Results')\n",
    "print(test_results_balanced_comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30fd8e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor técnica de balanceo: código 1\n",
      "Mejor modelo: RF\n"
     ]
    }
   ],
   "source": [
    "# Codificación de técnicas de balanceo\n",
    "# 1: NearMiss, 2: ADASYN, 3: Combinación ROS+RUS\n",
    "best_model_balancing = None\n",
    "best_balancing = None\n",
    "\n",
    "# Extraer el mejor F1-score de cada técnica y modelo\n",
    "f1_ros = cv_results_balanced['F1']\n",
    "f1_rus = cv_results_balanced2['F1']\n",
    "f1_nm = cv_results_balanced_nm['F1']\n",
    "f1_ad = cv_results_balanced_ad['F1']\n",
    "f1_comb = cv_results_balanced_comb['F1']\n",
    "\n",
    "f1_ros = f1_ros.astype(float)\n",
    "f1_rus = f1_rus.astype(float)\n",
    "f1_nm = f1_nm.astype(float)\n",
    "f1_ad = f1_ad.astype(float)\n",
    "f1_comb = f1_comb.astype(float)\n",
    "\n",
    "\n",
    "# Guardar los valores máximos y sus índices\n",
    "max_f1_ros = f1_ros.max()\n",
    "model_ros = f1_ros.idxmax()\n",
    "max_f1_rus = f1_rus.max()\n",
    "model_rus = f1_rus.idxmax()\n",
    "max_f1_nm = f1_nm.max()\n",
    "model_nm = f1_nm.idxmax()\n",
    "max_f1_ad = f1_ad.max()\n",
    "model_ad = f1_ad.idxmax()\n",
    "max_f1_comb = f1_comb.max()\n",
    "model_comb = f1_comb.idxmax()\n",
    "\n",
    "# Comparar los máximos entre técnicas\n",
    "f1_scores = [max_f1_ros, max_f1_rus, max_f1_nm, max_f1_ad, max_f1_comb]\n",
    "\n",
    "models = [model_ros, model_rus, model_nm, model_ad, model_comb]\n",
    "balancing_codes = [1, 2, 3, 4, 5]\n",
    "best_idx = int(np.argmax(f1_scores))\n",
    "best_model_balancing = models[best_idx]\n",
    "best_balancing = balancing_codes[best_idx]\n",
    "\n",
    "print(f\"Mejor técnica de balanceo: código {best_balancing}\")\n",
    "print(f\"Mejor modelo: {best_model_balancing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b52d1fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor técnica de balanceo en test: código 5\n",
      "Mejor modelo en test: RF\n"
     ]
    }
   ],
   "source": [
    "# Extraer el mejor F1-score de cada técnica y modelo en el dataset de test\n",
    "f1_ros_test = test_results_balanced['F1'].astype(float)\n",
    "f1_rus_test = test_results_balanced2['F1'].astype(float)\n",
    "f1_nm_test = test_results_balanced_nm['F1'].astype(float)\n",
    "f1_ad_test = test_results_balanced_ad['F1'].astype(float)\n",
    "f1_comb_test = test_results_balanced_comb['F1'].astype(float)\n",
    "\n",
    "max_f1_ros_test = f1_ros_test.max()\n",
    "model_ros_test = f1_ros_test.idxmax()\n",
    "max_f1_rus_test = f1_rus_test.max()\n",
    "model_rus_test = f1_rus_test.idxmax()\n",
    "max_f1_nm_test = f1_nm_test.max()\n",
    "model_nm_test = f1_nm_test.idxmax()\n",
    "max_f1_ad_test = f1_ad_test.max()\n",
    "model_ad_test = f1_ad_test.idxmax()\n",
    "max_f1_comb_test = f1_comb_test.max()\n",
    "model_comb_test = f1_comb_test.idxmax()\n",
    "\n",
    "f1_scores_test = [max_f1_ros_test, max_f1_rus_test, max_f1_nm_test, max_f1_ad_test, max_f1_comb_test]\n",
    "models_test = [model_ros_test, model_rus_test, model_nm_test, model_ad_test, model_comb_test]\n",
    "balancing_codes_test = [1, 2, 3, 4, 5]\n",
    "best_idx_test = int(np.argmax(f1_scores_test))\n",
    "best_model_balancing_test = models_test[best_idx_test]\n",
    "best_balancing_test = balancing_codes_test[best_idx_test]\n",
    "\n",
    "print(f\"Mejor técnica de balanceo en test: código {best_balancing_test}\")\n",
    "print(f\"Mejor modelo en test: {best_model_balancing_test}\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82039d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
